{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching required data...\n",
      "\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "Dropping rows with no label values in the target column...\n",
      "\n",
      "Dataset now contains 1078 rows and 150 columns...\n",
      "\n",
      "Preparing input features and output labels...\n",
      "['current smoker' 'former smoker' 'never smoked' 'tried smoking']\n",
      "['drink a lot' 'never' 'social drinker']\n",
      "['i am always on time' 'i am often early' 'i am often running late']\n",
      "['everytime it suits me' 'never' 'only to avoid hurting someone'\n",
      " 'sometimes']\n",
      "['few hours a day' 'less than an hour a day' 'most of the day'\n",
      " 'no time at all']\n",
      "['female' 'male']\n",
      "['left handed' 'right handed']\n",
      "['college/bachelor degree' 'currently a primary school pupil'\n",
      " 'doctorate degree' 'masters degree' 'primary school' 'secondary school']\n",
      "['no' 'yes']\n",
      "['city' 'village']\n",
      "['block of flats' 'house/bungalow']\n",
      "Checking for any empty values in the feature set...\n",
      "0\n",
      "*********************************************************************************************\n",
      "\n",
      "*** BASELINE MODEL ***\n",
      "\n",
      "Using Logistic Regression, not selecting any features...\n",
      "\n",
      "Validation Accuracy\n",
      "0.3563218390804598\n",
      "Test Accuracy\n",
      "0.30092592592592593\n",
      "*********************************************************************************************\n",
      "\n",
      "\n",
      "\n",
      "*** Feature Selection and Applying ML Models ***\n",
      "\n",
      "*********************************************************************************************\n",
      "\n",
      "*** PROPOSED MODEL ***\n",
      "\n",
      "Finding & selecting highly correlated features and applying SVC (30 features)...\n",
      "\n",
      "The accuracy of the model on: \n",
      "Validation Data:\n",
      "0.4942528735632184\n",
      "***\n",
      "Test Data:\n",
      "0.41203703703703703\n",
      "\n",
      "\n",
      "***\n",
      "Confusion Matrix for this model:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Score 1       0.87      0.87      0.87        15\n",
      "    Score 2       0.43      0.10      0.16        30\n",
      "    Score 3       0.32      0.48      0.38        50\n",
      "    Score 4       0.39      0.42      0.41        71\n",
      "    Score 5       0.45      0.38      0.41        50\n",
      "\n",
      "avg / total       0.43      0.41      0.40       216\n",
      "\n",
      "*********************************************************************************************\n",
      "\n",
      "\n",
      "Top 30 correlated features -- Using Random Forest Model\n",
      "Validation Accuracy\n",
      "0.39080459770114945\n",
      "Test Accuracy\n",
      "0.35185185185185186\n",
      "*********************************************************************************************\n",
      "\n",
      "Top 30 correlated features -- Using Logistic Regression Model\n",
      "The accuracy of the model on: \n",
      "Validation Data:\n",
      "0.4482758620689655\n",
      "Test Data: \n",
      "0.3333333333333333\n",
      "*********************************************************************************************\n",
      "Using Recursive Feature Elimination for selecting features and applying Logistic Regression...\n",
      "\n",
      "Fitting model on 30 features...\n",
      "The accuracy of the model on: \n",
      "Validation Data:\n",
      "0.42528735632183906\n",
      "Test Data:\n",
      "0.3472222222222222\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Score 1       0.43      0.54      0.48        24\n",
      "    Score 2       0.12      0.04      0.06        23\n",
      "    Score 3       0.36      0.37      0.37        57\n",
      "    Score 4       0.32      0.40      0.35        63\n",
      "    Score 5       0.36      0.31      0.33        49\n",
      "\n",
      "avg / total       0.33      0.35      0.33       216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''Defining Imports'''\n",
    "from pandas import *\n",
    "import numpy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import operator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "# print('Young People Survey Dataset - Task 2\\n\\n')\n",
    "\n",
    "'''Pulling the data from the CSV files'''\n",
    "#Loading data\n",
    "print('Fetching required data...\\n\\n')\n",
    "fname = 'young-people-survey/'+'responses.csv'\n",
    "f = open(fname, 'r') \n",
    "\n",
    "df = pandas.read_csv(fname)\n",
    "# print(df.describe())\n",
    "# print(len(df.columns))\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# X_sparse = resample(df(df['Spending on healthy eating'] == 1), n_samples = 70, random_state=10, replace=True)\n",
    "X_sparse = df[df['Spending on healthy eating'] == 1]\n",
    "# X_sparse\n",
    "\n",
    "X_resampled = resample(X_sparse, n_samples = 70, replace = True, random_state = 70)\n",
    "# print(X_resampled.shape)\n",
    "# X_resampled\n",
    "df = concat([df, X_resampled], axis = 0)\n",
    "# df.shape\n",
    "\n",
    "# df = new_df\n",
    "# df = df + X_resampled\n",
    "# df\n",
    "\n",
    "# print(df.shape)\n",
    "print('Preprocessing data...\\n')\n",
    "# Fill mean for numerical cols        \n",
    "for each_df in df:\n",
    "#     print(X[each_x].dtypes)\n",
    "\n",
    "    if df[each_df].dtypes != 'object' and each_df != 'Spending on healthy eating':\n",
    "        df[each_df].fillna(df[each_df].mean(), inplace=True)\n",
    "# print('\\n\\n\\n\\n')        \n",
    "# print(df.isnull().sum())\n",
    "\n",
    "# Fill mode for the categorical data cols:\n",
    "for each_df1 in df:\n",
    "    if df[each_df1].dtypes == 'object':\n",
    "        df[each_df1].fillna(statistics.mode(df[each_df1]), inplace = True)\n",
    "# print('\\n\\n\\n\\n')        \n",
    "# print(df.isnull().sum()) \n",
    "print('Dropping rows with no label values in the target column...\\n')\n",
    "df.dropna(inplace = True)\n",
    "# df.describe()\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "print('Dataset now contains %d rows and %d columns...\\n' %(df.shape[0], df.shape[1]))\n",
    "\n",
    "\n",
    "print('Preparing input features and output labels...')\n",
    "X = df.drop(['Spending on healthy eating'], axis = 1)\n",
    "# print(X.shape)\n",
    "Y = df['Spending on healthy eating']\n",
    "# print(X.shape, Y.shape)\n",
    "\n",
    "column_types = X.columns\n",
    "# print(column_types)\n",
    "le = LabelEncoder()\n",
    "for index, col in enumerate(column_types):\n",
    "    \n",
    "    if X[col].dtypes == 'object':\n",
    "        le.fit(X[col])\n",
    "#         print(le.classes_)\n",
    "        X[col] = le.transform(X[col])\n",
    "#         print(X[col])\n",
    "#         print('*********')\n",
    "\n",
    "# print(X.isnull().sum().sum())\n",
    "X = X.round()\n",
    "Y = Y.round()\n",
    "\n",
    "\n",
    "\n",
    "# Fill mean for numerical cols        \n",
    "for each_df in df:\n",
    "#     print(X[each_x].dtypes)\n",
    "\n",
    "    if df[each_df].dtypes != 'object' and each_df != 'Spending on healthy eating':\n",
    "        df[each_df].fillna(df[each_df].mean(), inplace=True)\n",
    "# print('\\n\\n\\n\\n')        \n",
    "# print(df.isnull().sum())\n",
    "\n",
    "\n",
    "import statistics\n",
    "# Fill mode for the categorical data cols:\n",
    "for each_df1 in df:\n",
    "    if df[each_df1].dtypes == 'object':\n",
    "        df[each_df1].fillna(statistics.mode(df[each_df1]), inplace = True)\n",
    "# print('\\n\\n\\n\\n')        \n",
    "# print(df.isnull().sum())        \n",
    "\n",
    "df.dropna(inplace = True)\n",
    "# df.describe()\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "X = df.drop(['Spending on healthy eating'], axis = 1)\n",
    "# print(X.shape)\n",
    "Y = df['Spending on healthy eating']\n",
    "# print(X.shape, Y.shape)\n",
    "\n",
    "\n",
    "column_types = X.columns\n",
    "# column_types\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "for index, col in enumerate(column_types):\n",
    "    \n",
    "    if X[col].dtypes == 'object':\n",
    "        le.fit(X[col])\n",
    "        print(le.classes_)\n",
    "        X[col] = le.transform(X[col])\n",
    "#         print(X[col])\n",
    "#         print('*********')\n",
    "print('Checking for any empty values in the feature set...')\n",
    "print(X.isnull().sum().sum())\n",
    "\n",
    "X = X.round()\n",
    "Y = Y.round()\n",
    "# X\n",
    "\n",
    "print('*********************************************************************************************\\n')\n",
    "\n",
    "print('*** BASELINE MODEL ***\\n')\n",
    "print('Using Logistic Regression, not selecting any features...\\n')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.round(), Y.round(), test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train.round(), Y_train.round(), test_size = 0.1)\n",
    "log_reg.fit(X_train, Y_train)\n",
    "log_reg_pred = log_reg.predict(X_val)\n",
    "print('Validation Accuracy')\n",
    "print(np.mean(log_reg_pred == Y_val))\n",
    "\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "print('Test Accuracy')\n",
    "print(np.mean(log_reg_pred == Y_test))\n",
    "\n",
    "print('*********************************************************************************************\\n')\n",
    "\n",
    "print('\\n\\n*** Feature Selection and Applying ML Models ***\\n')\n",
    "'''Feature Selection Techniques'''\n",
    "'''Finding correlation by Numpy's corrcoef '''\n",
    "\n",
    "corr_arr = {}\n",
    "for each_x in X:\n",
    "    corr_arr[each_x] = np.corrcoef(x=X[each_x], y=Y)[0,1]\n",
    "# print(corr_arr)\n",
    "sorted_corr_arr = sorted(corr_arr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "# type(sorted_corr_arr)\n",
    "X_corr = sorted_corr_arr[:30]\n",
    "new_X = []\n",
    "for row in range(0, len(X_corr)):\n",
    "    new_X.append(X_corr[row][0])\n",
    "# new_X\n",
    "\n",
    "X_corr = X[new_X]\n",
    "# X_corr\n",
    "\n",
    "print('*********************************************************************************************\\n')\n",
    "\n",
    "print('*** PROPOSED MODEL ***')\n",
    "print('\\nFinding & selecting highly correlated features and applying SVC (30 features)...\\n')\n",
    "\n",
    "\n",
    "'''Splitting data --- Top 30 correlated features -- SVC'''\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_corr.round(), Y.round(), test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train.round(), Y_train.round(), test_size = 0.1)\n",
    "\n",
    "svc_clf = SVC(C=2, kernel = 'rbf')\n",
    "svc_clf.fit(X_train, Y_train)\n",
    "l_svc_pred_val = svc_clf.predict(X_val)\n",
    "print('The accuracy of the model on: ')\n",
    "print('Validation Data:'),\n",
    "print(np.mean(l_svc_pred_val == Y_val))\n",
    "\n",
    "print('***')\n",
    "\n",
    "# svc_clf = SVC(multi_class = 'ovr', C=2)\n",
    "svc_clf.fit(X_train, Y_train)\n",
    "l_svc_pred = svc_clf.predict(X_test)\n",
    "print('Test Data:')\n",
    "print(np.mean(l_svc_pred == Y_test))\n",
    "# print(l_svc_pred)\n",
    "print('\\n')\n",
    "\n",
    "print('***')\n",
    "\n",
    "print('Confusion Matrix for this model:')\n",
    "\n",
    "target_names = ['Score 1', 'Score 2', 'Score 3', 'Score 4', 'Score 5']\n",
    "print(classification_report(Y_test, l_svc_pred, target_names=target_names))\n",
    "\n",
    "print('*********************************************************************************************\\n')\n",
    "\n",
    "'''Splitting data --- Top 30 correlated features -- Random Forest'''\n",
    "print('\\nTop 30 correlated features -- Using Random Forest Model')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_corr.round(), Y.round(), test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train.round(), Y_train.round(), test_size = 0.1)\n",
    "\n",
    "randF_clf = RandomForestClassifier(n_estimators = 6, max_depth = 6, max_features = 30, criterion = 'gini', warm_start = False)\n",
    "randF_clf.fit(X_train, Y_train)\n",
    "l_randF_pred = randF_clf.predict(X_val)\n",
    "print('Validation Accuracy')\n",
    "print(np.mean(l_randF_pred == Y_val))\n",
    "\n",
    "# randF_clf = RandomForestClassifier(max_features = 10, criterion = 'entropy', warm_start = False)\n",
    "randF_clf.fit(X_train, Y_train)\n",
    "l_randF_pred = randF_clf.predict(X_test)\n",
    "print('Test Accuracy')\n",
    "print(np.mean(l_randF_pred == Y_test))\n",
    "\n",
    "print('*********************************************************************************************')\n",
    "\n",
    "print('\\nTop 30 correlated features -- Using Logistic Regression Model')\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_corr.round(), Y.round(), test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train.round(), Y_train.round(), test_size = 0.1)\n",
    "log_reg.fit(X_train, Y_train)\n",
    "log_reg_pred = log_reg.predict(X_val)\n",
    "print('The accuracy of the model on: ')\n",
    "print('Validation Data:'),\n",
    "print(np.mean(log_reg_pred == Y_val))\n",
    "\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "print('Test Data: '),\n",
    "print(np.mean(log_reg_pred == Y_test))\n",
    "\n",
    "print('*********************************************************************************************')\n",
    "from sklearn.feature_selection import RFE\n",
    "print('Using Recursive Feature Elimination for selecting features and applying Logistic Regression...\\n')\n",
    "log_reg = LogisticRegression(multi_class='ovr', C = 2, solver='newton-cg', max_iter=105, n_jobs=20)\n",
    "\n",
    "rfe = RFE(log_reg, 30)\n",
    "print('Fitting model on 30 features...')\n",
    "fit_ = rfe.fit(X_train, Y_train)\n",
    "# print(fit_.support_)\n",
    "pred = rfe.predict(X_val)\n",
    "print('The accuracy of the model on: ')\n",
    "print('Validation Data:'),\n",
    "# print(np.mean(pred == Y_val))\n",
    "score = accuracy_score(Y_val.round(), pred)\n",
    "print(score)\n",
    "\n",
    "pred = rfe.predict(X_test)\n",
    "print('Test Data:'),\n",
    "# print(np.mean(pred == Y_val))\n",
    "score = accuracy_score(Y_test.round(), pred)\n",
    "print(score)\n",
    "print(classification_report(Y_test, pred, target_names=target_names))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
